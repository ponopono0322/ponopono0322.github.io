---
title:  "[ML]제주도 여행지 추천 모델 제작-3"
excerpt: "크롤링 그리고 Word2Vec"

categories:
  - Blog
tags:
  - [ML, Selenium, Crawling, Word2Vec]

toc: true
toc_sticky: true
 
date: 2021-08-28
last_modified_at: 2021-08-28
---
# 시작하기 앞서
## 지난 포스트 요약
1. 제주에 관한 데이터 수집
2. 머신러닝에 적용해볼만한 데이터 살펴보기
3. 데이터 오류와 대안방안 제시

## 이번 포스트에서는
크롤링을 통해 어떤 데이터를 수집했는지를 다룹니다.

1. 어떤 라이브러리를 사용했는가?
2. 어떤 데이터를 수집할까?
3. 어떤 방식으로 진행할까?
4. 다음 이야기

# 1. 어떤 라이브러리를 사용했는가?
이번 포스트에서 사용한 라이브러리는 다음과 같습니다.
1. Selenium
2. Time
3. Pandas

# 2. 어떤 데이터를 수집할까?
## 크롤링을 하게 된 결정적 이유
신용카드 데이터, 교통데이터 그리고 이동전화 접속량을 통해 일반적인 머신러닝 모델을 만드려고 했었다.   
이것은 우리가 목표했던 '개인 성향'의 부분이 결여될 수 밖에 없었기 때문에(이유는 이전 포스트 참고) 다른 방식으로 접근할 필요가 있었다.   
그 방안으로 나왔던 것이 연관분석과 Word2Vec이다. 장바구니 방식이라고 흔히 불리는 연관분석은 A가 나오면 B나 C가 나오는 '흔히 이걸사면 주로 저걸 많이 사더라 라는 방식'이고 Word2Vec은 단어간의 유사도를 파악해 나올 단어를 예측하거나, 유사도를 벡터 공간의 거리로 표현해주는 방법이다.   
이를 우리의 여행지에 대입하면 '주로 그 성향의 사람들은 그 여행지들을 가더라'라고 묶어 낼 수 있다는 것이다.   
그렇게 하려면 해시태그나 분류된 무언가가 필요하게 됐다. 이러한 것들은 정리된 파일이 없었기 때문에 직접 돌아다니며 수집해야했다.

## 비짓제주(www.visitjeju.net/kr) 크롤링
공공데이터포털이나 제주데이터허브의 데이터를 수집하면서 '비짓제주'라는 단어를 굉장히 많이 보게 되었다.   
그래서 뭔가 제공하는 서비스 인 것 같아 찾아보니, 제주도에 관한 정보들을 종합해둔 사이트였다.   
사이트를 첫 방문했을때 들었던 느낌은 '이거다!'였다. 관광지, 음식점, 숙박, 쇼핑으로 카테고리가 나뉜 것은 물론, 각종 해시태그와 테마여행 등 개인성향을 대표할 수 있는 키워드들이 잔뜩 있었다.   
그렇기 때문에 이 사이트를 기준으로 데이터를 수집하면 될 것 같다고 생각하여 크롤링을 시작하게 되었다.   
크롤링은 흔히 쓰이는 셀레니움을 사용해 반복적인 일을 컴퓨터에게 맡겼다.

크롤링 순서는
1. 관광지-음식점-숙박-쇼핑 순으로 돌기
2. 각 스팟별 링크를 저장하기
3. 저장된 링크로 이동해 데이터 추출   
으로 진행됐다.

우선 크롤링을 하기 전에 각 스팟별 개인 페이지에 대한 링크가 필요했다.

<script src="https://gist.github.com/ponopono0322/8f60608c998e75d162a6ba474db11f58.js"></script>

이를 혹시몰라 저장하고, 다시 불러와 쓰게 되었다.

<script src="https://gist.github.com/ponopono0322/8af9d57df2f3cdc9e8620f7f169dc0b9.js"></script>

위의 코드는 함수들만 정의한 것인데, 크롤링 할 때 반복적으로 쓰게 될 부분들을 분리한 것이다.   
그리고 실제 크롤링 하는 부분은 아래 코드이다.

<script src="https://gist.github.com/ponopono0322/3ca8f67245fc799afc0a17fb17018520.js"></script>

이렇게 크롤링 한 데이터는 다음과 같이 저장됐다.

<img width="1420" alt="캡처" src="https://user-images.githubusercontent.com/32767165/131217907-6204ed59-9a0a-4dae-ba35-ab51678a1afb.PNG">

이 외에 추후에 쓰게 될 카테고리 데이터를 크롤링 했다.

<script src="https://gist.github.com/ponopono0322/7c15cc54db8064489433b723587c2b47.js"></script>

위 코드를 실행했을 때 저장되는 데이터는 다음과 같다.

<img width="726" alt="1" src="https://user-images.githubusercontent.com/32767165/131218115-d9f87072-25de-490f-a0cd-f18ae3cc1217.PNG">

그 외에 실제로는 사용하지 않았지만, 필요할 것 같아 크롤링했던 코드이다.   
이 코드는 여행큐레이터라고, 월별 추천 관광지나 나름의 선정기준으로 이색 체험코스들을 칼럼으로 소개하는 페이지를 크롤링한 것이다.
이 부분도 역시 링크를 먼저 따고, 그 다음에 링크배열을 순회하면서 데이터를 가져왔다.

<script src="https://gist.github.com/ponopono0322/676fc0e45afc1c7e2b047dfe68ea7be7.js"></script>

## 다른 사이트들도 크롤링 할 필요성 대두
비짓제주 크롤링한 뒤 데이터를 써볼라고 하니, 딱히 무언가가 떠오르지 못했다. 왜냐하면 '개인맞춤'인데, 비짓제주의 해시태그 갯수로는 부족함을 느꼈다.   
게다가 같은 분류로 나누게 된다면, 우리들만의 차별성을 보기 어려웠다. 그렇기 때문에 다른 사이트에서도 해시태그를 가져올 필요성을 느끼게 되었다.    
그렇게 팀원들과 회의한 결과로 인스타그램, 네이버블로그, 트립어드바이저에서 추가로 데이터를 가져오기로 되었다.   
내가 담당한 부분은 네이버블로그였고, 트립어드바이저 일부도 같이 수행했기에 두 곳의 크롤링 방식을 간략히 설명하겠다.

## 네이버 블로그 크롤링
비짓제주내 등록된 관광지만 해도 1000건이 넘기 때문에, 우선 관광지 스팟 먼저 크롤링 하기로 했다.   
크롤링 순서는 다음과 같다.
1. 비짓제주의 관광지 목록 불러오기
2. 최신순으로 정렬 후 최대 150페이지 혹은 2021년에 작성된 블로그 링크만 가져오기
3. 가져온 링크배열을 순회하며 블로그 내용 가져오기

위 방법을 수행하는 중에 있었던 오류는 다음과 같았다.
1. 네이버 검색 버그인지, 같은 주소를 또 다른 페이지에서 보여주는 오류
2. 관광지 목록에 '&' 기호가 있으면 해당 기호가 나오기 전까지의 문자열만 검색하는 오류
3. 지명이나 동명같은, 다른 지방에도 같은 이름으로 불리는 경우에 제주도 보다 그 쪽이 더 유명하여 그 쪽 데이터로 보여주는 경우
4. (3)과 비슷한 이유로 원하지 않는 결과가 많이 섞이는 경우

일단 21년도 데이터만 가져온 이유는
1. 데이터가 너무 많아 크롤링에 투자할 시간적 여유가 없어서
2. 최신 트렌드에 맞추고 싶어서   
였다.

그리고 오류를 해결하기 위한 방안으로 같은 방식이지만, 정확도 순으로 100페이지를 순회하며 얻은 링크를 최신순과 비교하여 공통적으로 있는 링크만 가져왔다.

<script src="https://gist.github.com/ponopono0322/ee55cad0acdd972227e55af74ebb75ac.js"></script>

위 코드는 최신순으로 얻은 것이고, 51번째 줄을 정확도순으로 바꿔 다시 수행했다.

그리고 그렇게 얻은 링크를 간단히 합치면

<script src="https://gist.github.com/ponopono0322/7c6100e4a0ac1353e6427ec3d4783c6c.js"></script>

대부분 우리가 원하는 데이터를 가지고 있을 것이라 판단했다.

이 데이터를 기준으로 순회하며 데이터를 크롤링한 코드는 다음과 같고

<script src="https://gist.github.com/ponopono0322/408f1e45eac8c2b25de1754d7a20dcbe.js"></script>

이를 저장한 결과는 다음과 같이 나왔다.

<img width="724" alt="2" src="https://user-images.githubusercontent.com/32767165/131219182-28d27ee0-43a6-40c2-8329-979fa20d629f.PNG">

그림에서 보이듯이 이모지가 굉장히 많은데 이 부분들은 차후에 어떻게 정제했는지 다룬다.

## 트립어드바이저 크롤링
트립어드바이저에서는 음식점 정보를 가져왔다. 네이버블로그 크롤링한 방식과 동일하게 링크를 가져온 후, 내부 데이터를 긁어왔다.

<script src="https://gist.github.com/ponopono0322/a96b3911e4a9746fba866ee24cf70896.js"></script>

위 코드처럼 링크를 수집한 후

<script src="https://gist.github.com/ponopono0322/f8ee0c76089c20ff382e7cc3466b1ad9.js"></script>

이를 저장한 데이터는 다음과 같다.

<img width="712" alt="3" src="https://user-images.githubusercontent.com/32767165/131219351-1e30f9bb-6868-47ea-974c-72eb06125702.PNG">

# 3. 어떤 방식으로 진행할까?
리뷰 데이터가 있다면 당연히 먼저 떠오르는 것이 감정분석이다. 하지만 우리의 경우 긍정 대 부정으로 딱 나뉘는 것이 목표가 아니라, 주로 '그런 사람들이 그쪽으로 가더라' 라는 것이 필요했기 때문에, 해당 방식은 사용하지 못했다. 대신 우리는 Word2Vec의 유사성을 기반으로 나온 숫자데이터를 활용하여 전통적 선형 머신러닝이나 의사결정트리 같은 분류 문제로 가져가고 싶었다.

# 4. 다음 이야기
지금까지 크롤링한 리뷰데이터를 활용하여 Word2Vec을 사용하기 위한 전처리 과정, 그리고 전처리 이후 사용할 수많은 라이브러리들을 다룰 예정입니다.